\cleardoublepage
\chapter{Methodology}
\label{methodology}

This chapter presents the methodology used to complete the aims of the thesis,
primarily the use of inductive programming, via ADATE, to evolve interesting
game opponents. With that in mind, we describe the overall experimental method,
followed by the description of a prototype game to be used for simulation and
then we will briefly cover some details of the actual implementation of the
simulation platform and its specification.

We will be basing our experimental method on the one presented in
\citet{yannakakis2005ai}, due their high applicability to our goals. More
specifically, we will be using our own implementation of the Dead End game
testbed as described in \citet[Chap.~5]{yannakakis2005ai}, as well as the
interest metrics described in \citet[Chap.~2]{yannakakis2005ai}. The details of
the testbed and the interest metrics, as well as our changes to them, will be
noted throughout this chapter.

\section{The Dead End Game}
\label{sec:game}

The simulation environment we will be using is an adapted version of the Dead
End computer game used in \citet{yannakakis2005ai}; it is a predator-prey game
where the player (the prey) has to reach the goal before being captured by a
group of opponents (the predators). This game environment is sufficiently simple
that it's easy to model, but also sufficiently complex and dynamic to provide a
good basis for using evolutionary techniques to create interesting AI
strategies. The game will be considered from the viewpoint of the opponents (the
predators) in an attempt to evolve characters that exhibit the ability to
cooperate based on partial information, with the capability to play effectively
against a player following a fixed strategy.

\subsection{Description}
\label{sec:game-description}

In this section we will describe the Dead End game in sufficient detail to give
a good understanding for how it works, as well the ways in which our version
differs from the reference implementation.
\citep[see][Chap.~5]{yannakakis2005ai}

The game is played on a two-dimensional field of size 16cm x 16cm
\footnote{While we use the unit cm to refer to the units within the game, this
  is purely for convenience and is a completely virtual unit with no physical
  correspondence.} with a rectangular area at the top representing the goal
\marginpar{Insert size of goal here?}. The characters in the game are the player
character, named \emph{'Cat'}, represented as a circle of radius 0.75 cm, and an
arbitrary number of enemy characters, named \emph{'Dogs'}, represented as
squares of dimension 1.5 cm.

The aim for the Cat is to reach the exit from its starting position, situated
randomly at the bottom of the map, by avoiding the Dogs or to survive until the
end of the simulation, i.e. after a certain amount of simulation steps. On the
other hand, the aim of the Dogs is to capture the Cat before it reaches the exit
or the simulation ends.

Since there are more Dogs than there are Cats on the playing field, they are
given a handicap to even the playing field. In our implementation, the Cat moves
at a fixed rate of 2 cm per simulation tick, while the dogs move at $3/4$ that
speed, 1.5 cm per simulation tick. In addition, it is important to note that
the Dogs have the property of permeability, i.e. they can occupy the same space
as other Dogs. Given the speed handicap the Dogs have, it is impossible for a
single Dog to catch the Cat, so the Dogs must cooperate to trap and catch the
Cat. This is where the opportunity arises for emerging interesting AI behaviour.

At the beginning of the game the characters are positioned so they are
sufficiently spaced out. As mentioned, the Cat starts at a random position flush
with the bottom of the field, whereas the Dogs start at a random position in the
upper half of the playing field.

Then, for each simulation tick, the following happens:

\begin{enumerate}
\item All entities (Cat and Dogs) in the game gather information from the
  playing field, run their AI routine, and produces a movement decision: up,
  down, left, or right.
\item All entities are moved according to their movement decisions.
\item The field is checked for any collisions. If there are any, the game is
  marked as over, and the win condition is checked. If the Cat has collided with
  the goal, the game is considered won, if any of the Dogs collided with the
  Cat, the game is considered lost, and if both occurs the tie is broken by
  considering the game won. (The Cat narrowly escapes, with a suspiciously
  teeth-shaped mark)
\item If the game is not over yet, but the amount of simulation ticks is greater
  than 50, the game is considered over and won.
\item If the game is over, a new game is started with a new random cat position,
  but the same dog positions. \marginpar{Should we do this?}
\end{enumerate}

\subsection{The Cat}
\label{sec:cat}

To be able to evolve good behaviour for our characters (the Dogs), it is
necessary to have a competent player character, as the behaviour of the Dogs is
strongly related to the behaviour of the player character. As it isn't feasible
to provide the player character with human input during the simulation process,
it is necessary to provide one or more strategies for the player to execute in
an attempt to reach its goal. For the Dogs to be capable of diverse behaviour it
is preferred to have several behaviour for the player, so in our case we have
implemented two fixed strategy behaviours for the Cat.

These strategies are implement as AI functions which take as input a complete
state of the field containing the following:
\marginpar{Maybe a list like this is overkill?}
\begin{description}
\item[Self] The \((x,y)\) coordinates of the current Dog.
\item[Cat position] The \((x,y)\) coordinates of the Cat.
\item[All Dogs] A list of the \((x,y)\) coordinates of all the Dogs.
\item[Goal position] The \((x,y)\) coordinates of the Goal.
\end{description}

and produce as its output a movement direction: left, right, up, or down.

\subsubsection{Exit-Achieving Cat}
\label{sec:exit-achieving-cat}

This is a very simple Cat behaviour. It simply chooses the movement direction
that reduces the coordinate which has the greatest relative direction from the
Goal. If the Goal has position \((8,1)\) and the cat has position \((7,10)\),
the Cat would choose to move up, as the Y direction has the biggest difference.

\subsubsection{Potential Field-Based Cat}
\label{sec:potent-field-based}

This is a more complex and efficient Cat behaviour based on a Artificial
Potential Field (APF), where the cat is attracted or repelled by objects in the
playing field, and moves along the path of least resistance towards the Goal.
The implementation is heavily based on the one in
\citet[Chap.~5.1.1.3]{yannakakis2005ai} and considers points along the path to
the Goal as attractive, and the Dogs as strongly repulsive.

The overall effect of the forces on the field gives the cat a map of movement
costs by plotting the function $C(x,y)$:

\begin{equation}
  \label{eq:1}
  C(x,y) = \Delta_E(x,y) + D(x,y)
\end{equation}
\begin{equation}
  \label{eq:2}
  \Delta_E(x,y) = \sqrt{(x_e - x)^2 + (y_e - y)^2}
\end{equation}
\begin{equation}
  \label{eq:3}
  D(x,y) = \sum^N_{i=1} \frac{\rho}{|x_{d,i} - x| + |y_{d,i}-y|}
\end{equation}

where \(N\) is the number of Dogs, \((x_e,y_e)\) is the center of the Goal,
\((x_{d,i},y_{d,i})\) is the center of the \(i^th\) dog, \(\rho\) is the cost of
a dog in the APF (which in our implementation is 1000, as it is in the reference
implementation).

This field allows the Cat to select the direction that will incur the lowest
costs by plotting $C(x,y)$ at 0.5 cm intervals for 2 cm in each movement
direction from the Cat's center coordinate, computing the average cost of moving
in that direction, and selecting the direction with the lowest movement cost.

This strategy is intended to represent a very good strategy for the Cat, on
level with the performance of a Human player, and as such is well suited as a
surrogate for a human player in the simulation.

\subsection{The Dogs}
\label{sec:dogs}

This point marks the biggest deviation from the reference implementation, which
utilized Dogs controlled by Feed-forward Neural Networks
\citep[Chap.~5.1.2]{yannakakis2005ai}.  Our dogs will instead be controlled by a
Standard ML function generated by the ADATE system. The generated function
accepts input similar to the input given to the the neural network described in
the reference implementation, and produce similar output.

\subsubsection{Input}
\label{sec:input}

The input to the Dogs AI function is a snapshot of the state of the field with
the following values:

\begin{description}
\item[Self] The \((x,y)\) coordinates of the current Dog.
\item[Cat position] The \((x,y)\) coordinates of the Cat.
\item[Nearest k dogs] A list of the \((x,y)\) coordinates of the \(k\) closest
  dogs.
\item[Goal position] The \((x,y)\) coordinates of the Goal.
\end{description}

Take notice that the Dogs do not have access to the position of all the dogs in
the field, but only the nearest \(k\) dogs, this places limitations on how
closely they can cooperate.

\subsubsection{Output}
\label{sec:output}

The output is the Dog's chosen movement direction: left, right, up, or down.


\section{Interest Metrics}
\label{sec:interest-metrics}

As given in \citet{yannakakis2005ai}, there are three criteria that define an
interesting, and as such entertaining, game:

\begin{enumerate}
\item \emph{The game must not be too hard, nor too easy.} The game is
  interesting when the opponents strike a balance between ``Hard Fun'' and
  ``Easy Fun'' \citep{lazzaro2004we}, in that they are not too hard to dodge,
  but also provide some level of challenge.
\item \emph{The behaviour of the opponents must be diverse over games.} This
  requires the opponents to change their tactics or behaviour over subsequent
  games, which make them less predictable, and thus more entertaining.
\item \emph{The opponents must be dynamic and exhibit spatial diversity.} The
  opponents should move around and try to cover the entire field, instead of
  staying in a certain area of the field. This gives the impression that they're
  actually intelligent entities, and thus making them more entertaining.
\end{enumerate}

From these criteria, we derived a fitness function much like the one in
\citet[Chap.~2.2.2]{yannakakis2005ai}. The fitness function combines three
metrics, each quantifying a specific criterion.

To be able to use this fitness function to evaluate the interest level of an
opponent the game must be played a certain amount of times \(N\), for a maximum
of \(t_{max}\) ticks each time. During these games we record two collections of
data for each game \(k\):

\begin{enumerate}
   \item The amount of ticks \(t_k\) taken to finish the game, either as a
   result of a win or a loss.

   \item the amount of times \(\nu_{ik}\) each 1cm x 1cm cell \(i\) of the field
   was visited by any of the opponents present on the field.

\end{enumerate}

Then we can calculate interest values for each of the three metrics and combine
them into a single interest value as described in the following sections.

\subsection{Appropriate level of challenge}
\label{sec:appr-level-chall}

Following the first criterion, quantifying the level of challenge in the
opponents, we got the following metric:

\begin{equation}
  \label{eq:4}
  T = [ 1- (avg(t_k)/max(t_k))]^{p_1}
\end{equation}

Here, \(avg(t_k)\) is the average number of ticks taken to finish the game over
the \(N\) trials; \(max(t_k)\) is the maximum number of ticks \(t_k\) taken over
the \(N\) trials, bounded by \(t_{max}\); \(p_1\) is a weighting parameter to be
described in Section~\ref{sec:weights}.

The metric in \eqref{eq:4} increases as the diversity in the amount of ticks
taken to finish the game increases, signifying that the game is interesting when
the level of difficulty does not stay constant. This ensures that the game is
neither too easy or too hard.

\subsection{Diversity over games}
\label{sec:diversity-over-games}

Quantifying the second criterion, diversity across games, gave us the following
metric:

\begin{subequations}
  \begin{align}
    \label{eq:5}
    S &= (\sigma_{t_k} / \sigma_{max})^{p_2}\\
    \sigma_{max} &= \frac{1}{2} \sqrt{\frac{N}{N-1}} (t_{max} - t_{min})
  \end{align}
\end{subequations}

Here, \(\sigma_{t_k}\) is the standard deviation of \(t_k\) across the \(N\)
trials; \(\sigma_{max}\) is an estimate of the maximum value for the standard
deviation of \(t_k\); \(t_{min}\) is the estimated minimum amount of ticks
required for the game to be over (3.0 in our implementation); \(p_2\) is a
weighting parameter to be described in Section~\ref{sec:weights}.

The metric in \eqref{eq:5} increases as the spread between the amount of ticks
taken to finish each game increases over the \(N\) trials. This promotes
opponents that have high diversity in their behaviour.

\subsection{Spatial Diversity}
\label{sec:spatial-diversity}

The third criterion, quantifying the spatial diversity of the opponents, gives
us the following metric, for each game \(n\) in the \(N\) trials:

\begin{equation}
  \label{eq:6}
  H_n = \left[ -\frac{1}{log V_n} \sum_i \frac{\nu_{in}}{V_n}
    log\left(\frac{\nu_{in}}{V_n}\right) \right]^{p_3}
\end{equation}

Here, \(V_n\) is the total number of visits for all cells, and \(p_3\) is a
weighting parameter to be described in Section~\ref{sec:weights}.

The metric in \eqref{eq:6} is a measure of the entropy of cell visits for a
single game. The full metric for spatial diversity is the average value
\(avg(H_n)\) over the \(N\) trials. So, the higher the average entropy of cell
visits over all games, the more interesting the opponents. This ensures
opponents that move around actively, instead of staying in a small area of the
field.

\subsection{Metrics combined}
\label{sec:metrics-combined}

To get the final fitness function, we combine these three metrics in the following
way:

\begin{equation}
  \label{eq:7}
  I = \frac{\gamma T + \delta S + \varepsilon * avg(H_n)}{\gamma + \delta + \varepsilon}
\end{equation}

Here, \(\gamma\), \(\delta\), \(\varepsilon\) are weighting parameters for each
criterion that will differ depending on the game that is being evaluated, these
will be described further in Section~\ref{sec:weights}.

The combined metric \eqref{eq:7} gives us a combined measure of how interesting
the tested opponent is for the game to be tested.

\subsection{Weights}
\label{sec:weights}

There are six weights that can be used to tune the interest value to emphasize
certain metrics over others. They are divided into two categories:

\begin{itemize}
  \item Power parameters, inherent to the fitness function: \(p_1\), \(p_2\) and \(p_3\).
  \item Criterion parameters, tuning parameters for each game: \(\gamma\), \(\delta\) and \(\varepsilon\).
\end{itemize}

We used the same values for these weighting parameters as described in
\citet[Chap.~2.4]{yannakakis2005ai} (\(p_1\), \(p_2\) and \(p_3\)) and
\citet[Chap.~5.3.3]{yannakakis2005ai} (\(\gamma\), \(\delta\) and
\(\varepsilon\)). Specifically, we set the parameters as such:

\begin{itemize}

   \item \(p_1=0.5\), \(p_2=1\), and \(p_3=4\).
   \item \(\gamma=1\), \(\delta=2\) and \(\varepsilon=1\).
 \end{itemize}

\section{Experiment}
\label{sec:experiment}

\marginpar{Also use online learning methods to improve (?).} The experimental
method followed had three main steps: implementing the simulation platform and
specification, generating promising candidate opponents for further evaluation,
and evaluating the generated candidate opponents vs. pre-programmed opponents.
%These three steps are introduced here, then expanded on in further sections.

The simulation platform consisted of two parts: a simulation environment and a
specification for use in ADATE. The simulation environment was an ADATE-ML
implementation of the Dead End game, included in the specification, and an
accompanying Python version for visualizing. The specification, in addition to
the specification, contained an input generation function, an evaluation
function for generated opponents, some support code needed by these, and various
parameters to configure the ADATE system.

We then let the ADATE system run for a period of XXX\marginpar{Insert time here}
to generate individuals. The generated individuals were examined and various
individuals were picked out for further examination were picked out based on
their interest metrics and some other factors.

To examine the chosen opponent individuals further we put them up against pre-
programmed AI player characters, while monitoring their behaviour and
performance in higher detail. This data was then collated and compared against
the performance of a selection pre-programmed opponent behaviour.

\section{Simulation platform}
\label{sec:sim-platform}

The simulation platform used in our experiment had two main parts: the
simulation environment, the Dead End game as described in
Section~\ref{sec:game}, and a specification for the ADATE system that will be
used to generate opponents.

\subsection{Simulation environment}
\label{sec:sim-environment}

When we implemented the Dead End game, our simulation environment, we made two
separate implementations of it with slightly different goals. One was
implemented in ADATE-ML to be used as the simulation platform in our
specification; the other was implemented in Python using the Pygame framework
\citep{pygame} to serve as a way to visualize the game, as well as to leave the
option open for having humans play the game in place of AI if necessary.

As the ADATE-ML implementation was created with the sole goal of being used in
the specification, it lacked any of the structure needed for it to resemble a
real consumer game; therefore, it was not well suited for visualizing the
platform, supporting alternative methods of play or collecting data other than
what was needed to measure the performance of individuals.

\marginpar{Include picture here} To address this problem, and to give us a
better platform to study the behaviour of generated individuals, we made a
separate implementation of the game in Python using the Pygame framework
\citep{pygame}. This implementation was written in a manner more resembling a
consumer game. It included facilities to allow humans to play the game in place
of an AI player character; in addition, it contained much better facilities for
gathering data about the performance of the characters in the game.

\subsection{Specification}
\label{sec:specification}



%%% Local Variables:
%%% TeX-master: "main"
%%% End:
